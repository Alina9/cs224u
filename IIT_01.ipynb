{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from equality_datasets import get_equality_dataset, get_IIT_equality_dataset\n",
    "from IIT_torch_shallow_neural_classifier import TorchShallowNeuralClassifierIIT\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_interventionable_model import InterventionableLayeredModel\n",
    "from torch_rnn_classifier import TorchRNNClassifier\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Hierarchical Equality Dataset](#Hierarchical-Equality-Dataset)\n",
    "2. [High-Level Tree-Structured Algorithm](#The-High-Level-Tree-Structured-Algorithm)\n",
    "3. [A Fully-Connected Feed-Forward Neural Network](#A-Fully-Connected-Feed-Forward-Neural-Network)\n",
    "4. [Causal Abstraction](#Causal-Abstraction)\n",
    "5. [Interchange Intervention Training (IIT)](#Interchange-Intervention-Training-(IIT))\n",
    "\n",
    "## Hierarchical Equality Dataset  \n",
    "[Geiger, Carstensen, Frank, and Potts (2020)](https://arxiv.org/abs/2006.07968)\n",
    "\n",
    "We will use a hierarchical equality task to present IIT. We define the hierarchical equality task as follows: The input is two pairs of objects and the output is **true** if both pairs contain the same object or if both pairs contain different objects and **false** otherwise. For example, AABB and ABCD are both labeled **true** while ABCC and BBCD are both labeled **false**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The High-Level Tree-Structured Algorithm\n",
    "\n",
    "Let $\\mathcal{A}$ be the simple tree structured algorithm that solves this task by applying a simple equality relation three times: Compute whether the first two inputs are equal, compute whether the second two inputs are equal, then compute whether\n",
    "the truth-valued outputs of these first two computations are equal. We visually define $\\mathcal{A}$ below and then define a python function that computes $\\mathcal{A}$, possibly under an intervention that sets $V_1$ and/or $V_2$ to fixed values.\n",
    "\n",
    "<img src=\"fig/IIT/PremackFunctions.png\" width=\"500\"/>\n",
    "<img src=\"fig/IIT/PremackGraph.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_A(input, intervention):\n",
    "    graph = dict()\n",
    "    for i, object in enumerate(input):\n",
    "        graph[\"input\" + str(i+1)] = object\n",
    "    if \"V1\" in intervention:\n",
    "        graph[\"V1\"] = intervention[\"V1\"]\n",
    "    else:\n",
    "        graph[\"V1\"] = graph[\"input1\"] == graph[\"input2\"]\n",
    "    if \"V2\" in intervention:\n",
    "        graph[\"V2\"] = intervention[\"V2\"]\n",
    "    else:\n",
    "        graph[\"V2\"] = graph[\"input3\"] == graph[\"input4\"]\n",
    "    graph[\"output\"] = graph[\"V1\"] == graph[\"V2\"]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with no intervention\n",
    "\n",
    "First, observe the behavior of the algorithm whhen we provide the input **(pentagon,pentagon, triangle, square)** with no intervention. We show this visually and by using our **compute_A** function.\n",
    "\n",
    "<img src=\"fig/IIT/PremackNoIntervention.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': 'pentagon',\n",
       " 'input2': 'pentagon',\n",
       " 'input3': 'triangle',\n",
       " 'input4': 'square',\n",
       " 'V1': True,\n",
       " 'V2': False,\n",
       " 'output': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_A((\"pentagon\", \"pentagon\", \"triangle\", \"square\"), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with an intervention\n",
    "\n",
    "Observe the behavior of the algorithm whhen we provide the input **(square,pentagon, triangle, triangle)** with an intervention setting **V1** to **False**. We show this visually and by using our **compute_A** function.\n",
    "\n",
    "<img src=\"fig/IIT/PremackIntervention.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': 'square',\n",
       " 'input2': 'pentagon',\n",
       " 'input3': 'triangle',\n",
       " 'input4': 'triangle',\n",
       " 'V1': True,\n",
       " 'V2': True,\n",
       " 'output': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_A((\"square\", \"pentagon\", \"triangle\", \"triangle\"), {\"V1\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm with an interchange intervention\n",
    "\n",
    "Finaally, observe the behavior of the algorithm when we provide the base input **(square,pentagon, triangle, triangle)** with an intervention setting **V1** to be the value it would be for the source input **(pentagon,pentagon, triangle, square)**. We show this visually and by using our **compute_A** function.\n",
    "\n",
    "<img src=\"fig/IIT/PremackIntervention.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': 'pentagon',\n",
       " 'input2': 'pentagon',\n",
       " 'input3': 'triangle',\n",
       " 'input4': 'square',\n",
       " 'V1': False,\n",
       " 'V2': False,\n",
       " 'output': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_interchange_A(base,source, variable):\n",
    "    return compute_A(base, {variable:compute_A(source, {})[variable]})\n",
    "    \n",
    "compute_interchange_A((\"pentagon\", \"pentagon\", \"triangle\", \"square\"), (\"square\", \"pentagon\", \"triangle\", \"triangle\"), \"V1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Fully-Connected Feed-Forward Neural Network\n",
    "\n",
    "We will train a two layer feed-forward neural network on this task where each object has a random vector assigned to it and the objects in training are disjoint from the objects seen in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 553. Training loss did not improve more than tol=1e-05. Final error is 0.0003255244682804914."
     ]
    }
   ],
   "source": [
    "\n",
    "TRUE_LABEL = 1\n",
    "FALSE_LABEL = 0\n",
    "    \n",
    "embedding_dim = 5\n",
    "X_train, X_test, y_train, y_test, test_dataset = get_equality_dataset(embedding_dim,10000)\n",
    "\n",
    "model = TorchShallowNeuralClassifier(hidden_dim=4*embedding_dim, hidden_activation=torch.nn.ReLU(), num_layers=3)\n",
    "_ = model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that this neural network achieves near perfect performance on its test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0364,  0.0224, -0.3713, -0.0588,  0.2444,  0.0364,  0.0224, -0.3713,\n",
      "        -0.0588,  0.2444, -0.4442,  0.1645, -0.2804, -0.3022,  0.3193, -0.3240,\n",
      "         0.1784,  0.3509,  0.2537, -0.3696], dtype=torch.float64) 0\n",
      "Train Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0], y_train[0])\n",
    "preds = model.predict(X_train)\n",
    "print(\"Train Results\")\n",
    "print(classification_report(y_train, preds))\n",
    "preds = model.predict(X_test)\n",
    "print(\"\\n\\n\\nTest Results\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The network with no intervention\n",
    "\n",
    "First, observe the behavior of the network when we provide the input **(pentagon,pentagon, triangle, square)** with no intervention. We assign each shape a random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-0.1468924697219567, 0.08058055715288948, -0.00780593997868273, -0.09137492307583517, 0.37462958731792295, -0.1468924697219567, 0.08058055715288948, -0.00780593997868273, -0.09137492307583517, 0.37462958731792295, 0.15957464170810198, 0.23421546883109567, 0.2770979368015196, 0.33923462016878914, -0.40979122498799136, -0.3828546875372202, 0.22214910510358454, 0.47936303417244075, -0.4888289894644897, 0.15564735672704422]]\n",
      "\n",
      "Layer 0: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.6438, 0.0000, 0.4686, 0.0000, 0.2442, 0.1763, 0.0000, 0.0000,\n",
      "         0.0055, 0.4739, 0.0000, 0.0000, 0.0092, 0.0000, 0.1003, 0.0000, 0.0000,\n",
      "         0.1359, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 1: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.9234, 0.0949, 0.4198, 0.0000, 0.0256, 0.0000, 0.0000, 0.3851, 0.3467,\n",
      "         0.0000, 0.3639, 0.0000, 0.0000, 0.2465, 0.2948, 0.0000, 0.4032, 0.2969,\n",
      "         0.4415, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 2: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 1.1027, 0.0000, 0.0000, 0.0000, 0.0000, 0.9665, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.1404, 0.0000, 1.2535, 0.0000, 0.0000, 1.4600, 0.4888,\n",
      "         0.0000, 1.0620]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 3: Linear(in_features=20, out_features=2, bias=True)\n",
      "\n",
      "Neural Activations: tensor([[ 7.7798, -7.8989]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "pentagon = [random.uniform(-0.5,0.5) for _ in range(embedding_dim)]\n",
    "triangle = [random.uniform(-0.5,0.5) for _ in range(embedding_dim)]\n",
    "square = [random.uniform(-0.5,0.5) for _ in range(embedding_dim)]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input:\",[[*pentagon,*pentagon,*triangle,*square]])\n",
    "for k in range(len(model.layers)):\n",
    "    get_coord = {\"layer\":k, \"start\":0, \"end\":embedding_dim*4}\n",
    "    print(f\"\\nLayer {k}:\", model.layers[k])\n",
    "    print(\"\\nNeural Activations:\", model.retrieve_activations(torch.tensor([[*pentagon,*pentagon,*triangle,*square]]), get_coord, None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The network with an intervention\n",
    "\n",
    "Now, observe the behavior of the network when we provide the input **(pentagon,pentagon, triangle, square)** with an intervention that zeros out five neurons after the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-0.1468924697219567, 0.08058055715288948, -0.00780593997868273, -0.09137492307583517, 0.37462958731792295, -0.1468924697219567, 0.08058055715288948, -0.00780593997868273, -0.09137492307583517, 0.37462958731792295, 0.15957464170810198, 0.23421546883109567, 0.2770979368015196, 0.33923462016878914, -0.40979122498799136, -0.3828546875372202, 0.22214910510358454, 0.47936303417244075, -0.4888289894644897, 0.15564735672704422]]\n",
      "\n",
      "Layer 0: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.6438, 0.0000, 0.4686, 0.0000, 0.2442, 0.1763, 0.0000, 0.0000,\n",
      "         0.0055, 0.4739, 0.0000, 0.0000, 0.0092, 0.0000, 0.1003, 0.0000, 0.0000,\n",
      "         0.1359, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 1: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3851, 0.3467,\n",
      "         0.0000, 0.3639, 0.0000, 0.0000, 0.2465, 0.2948, 0.0000, 0.4032, 0.2969,\n",
      "         0.4415, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 2: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.1819, 0.5323, 0.4157, 0.6224, 0.5768, 0.1968, 0.4671, 0.3697,\n",
      "         0.0000, 0.4677, 0.0531, 0.3808, 0.1635, 0.5662, 0.0000, 0.3467, 0.4433,\n",
      "         0.5137, 0.2045]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 3: Linear(in_features=20, out_features=2, bias=True)\n",
      "\n",
      "Neural Activations: tensor([[-4.7269,  4.8842]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "set_coord = {\"layer\":1, \"start\":0, \"end\":embedding_dim, \"intervention\": torch.tensor([[0 for _ in range(embedding_dim)]])}\n",
    "\n",
    "print(\"Input:\",[[*pentagon,*pentagon,*triangle,*square]])\n",
    "for k in range(len(model.layers)):\n",
    "    get_coord = {\"layer\":k, \"start\":0, \"end\":embedding_dim*4}\n",
    "    print(f\"\\nLayer {k}:\", model.layers[k])\n",
    "    print(\"\\nNeural Activations:\", model.retrieve_activations(torch.tensor([[*pentagon,*pentagon,*triangle,*square]]), get_coord, set_coord))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The network with an interchange intervention\n",
    "\n",
    "Finally, observe the behavior of the network when we provide the input **(pentagon,pentagon, triangle, square)** with an intervention that sets five neurons after the first hidden layer to the values they achieve for the source input  **(square, pentagon, triangle, triangle)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[-0.1468924697219567, 0.08058055715288948, -0.00780593997868273, -0.09137492307583517, 0.37462958731792295, -0.1468924697219567, 0.08058055715288948, -0.00780593997868273, -0.09137492307583517, 0.37462958731792295, 0.15957464170810198, 0.23421546883109567, 0.2770979368015196, 0.33923462016878914, -0.40979122498799136, -0.3828546875372202, 0.22214910510358454, 0.47936303417244075, -0.4888289894644897, 0.15564735672704422]]\n",
      "\n",
      "Layer 0: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.6438, 0.0000, 0.4686, 0.0000, 0.2442, 0.1763, 0.0000, 0.0000,\n",
      "         0.0055, 0.4739, 0.0000, 0.0000, 0.0092, 0.0000, 0.1003, 0.0000, 0.0000,\n",
      "         0.1359, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 1: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.8636, 0.4841, 0.2193, 0.5431, 0.0000, 0.0000, 0.3851, 0.3467,\n",
      "         0.0000, 0.3639, 0.0000, 0.0000, 0.2465, 0.2948, 0.0000, 0.4032, 0.2969,\n",
      "         0.4415, 0.0000]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 2: ActivationLayer(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Neural Activations: tensor([[0.0000, 0.1969, 0.8776, 0.7200, 0.9971, 0.8565, 0.3353, 0.8209, 0.9587,\n",
      "         0.0000, 0.8599, 0.0000, 0.7895, 0.0000, 0.9622, 0.0000, 0.2153, 0.8869,\n",
      "         0.8579, 0.0020]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "\n",
      "Layer 3: Linear(in_features=20, out_features=2, bias=True)\n",
      "\n",
      "Neural Activations: tensor([[-9.8724, 10.1956]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "intervention = model.retrieve_activations(torch.tensor([[*square,*pentagon,*triangle,*triangle]]), {\"layer\":1, \"start\":0, \"end\":embedding_dim},None)\n",
    "\n",
    "set_coord = {\"layer\":1, \"start\":0, \"end\":embedding_dim, \"intervention\": intervention}\n",
    "\n",
    "print(\"Input:\",[[*pentagon,*pentagon,*triangle,*square]])\n",
    "for k in range(len(model.layers)):\n",
    "    get_coord = {\"layer\":k, \"start\":0, \"end\":embedding_dim*4}\n",
    "    print(f\"\\nLayer {k}:\", model.layers[k])\n",
    "    print(\"\\nNeural Activations:\", model.retrieve_activations(torch.tensor([[*pentagon,*pentagon,*triangle,*square]]), get_coord, set_coord))\n",
    "\n",
    "\n",
    "def interchange_intervention(model, base, source, int_coord, get_coord):\n",
    "    intervention = model.retrieve_activations(source, int_coord,None)\n",
    "    int_coord[\"intervention\"] = intervention\n",
    "    return model.retrieve_activations(base, get_coord, int_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Abstraction\n",
    "\n",
    "We defined a **high-level tree structured agorithm** that solves the hierarchical equality task.\n",
    "\n",
    "We trained a **low-level fully connected neural network** that solves the hierarchical equality task.\n",
    "\n",
    "A formal theory of **causal abstraction** describes the conditions that must hold for the high-level tree structured algorithm to be a **simplified and faithful description** of the neural network: \n",
    "\n",
    "**An algorithm is a causal abstraction of a neural network if and only if for all base and source inputs, the algorithm and network provides the same output under an aligned interchange intervention.**\n",
    "\n",
    "Below, we define an alignment between the neural network and the algorithm and a function to compute the **interchange intervention training accuracy** for a high-level variable, which is the percentage of aligned interchange interventions that the network and algorithm produce the same output on. When the IIT accuracy is 100%, the causal abstraction relation holds between the network and a simplified version of the algorithm where only one high-level variable exists.\n",
    "\n",
    "We compute the IIT accuracy on our toy domain where each entity is either a pentagon, square, or triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "alignment = {\"V1\": {\"layer\":1, \"start\":0, \"end\":embedding_dim}, \"V2\": {\"layer\":1, \"start\":embedding_dim+1, \"end\":embedding_dim*2}}\n",
    "\n",
    "def convert_input(tensor, embedding_dim):\n",
    "    return [tuple(tensor[0,embedding_dim*k:embedding_dim*(k+1)].flatten().tolist()) for k in range(4)]\n",
    "\n",
    "def compute_IIT_accuracy(variable, model):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for base in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "        for source in itertools.product([pentagon, triangle, square], repeat=4):\n",
    "            basetensor = torch.cat([torch.tensor([base[k]]) for k in range(4)], 1)\n",
    "            sourcetensor = torch.cat([torch.tensor([source[k]]) for k in range(4)],1)\n",
    "            algorithm_output = compute_interchange_A(convert_input(basetensor, embedding_dim), convert_input(sourcetensor, embedding_dim), variable)\n",
    "            if algorithm_output[\"output\"]:   \n",
    "                labels.append(TRUE_LABEL)\n",
    "            else:\n",
    "                labels.append(FALSE_LABEL)\n",
    "            get_coord = {\"layer\":3, \"start\":0, \"end\":2}\n",
    "            network_output = interchange_intervention(model, basetensor, sourcetensor,alignment[variable], get_coord).argmax(axis=1)\n",
    "            predictions.append(int(network_output))\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we have low IIT accuracy for both **V1** and **V2**, meaning that under this alignment the neural network does not compute either variable. We have no evidence that this network computes simple equality relations to solve this hierarchical equality task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55      2916\n",
      "           1       0.65      0.75      0.70      3645\n",
      "\n",
      "    accuracy                           0.64      6561\n",
      "   macro avg       0.63      0.62      0.62      6561\n",
      "weighted avg       0.64      0.64      0.63      6561\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55      2916\n",
      "           1       0.63      0.59      0.61      3645\n",
      "\n",
      "    accuracy                           0.58      6561\n",
      "   macro avg       0.58      0.58      0.58      6561\n",
      "weighted avg       0.59      0.58      0.58      6561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(*compute_IIT_accuracy(\"V1\", model)))\n",
    "print(classification_report(*compute_IIT_accuracy(\"V2\", model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interchange Intervention Training (IIT)\n",
    "\n",
    "Original IIT [Geiger\\*, Wu\\*, Lu\\*, Rozner, Kreiss, Icard, Goodman, and Potts (2021)](https://arxiv.org/abs/2112.00826)\n",
    "\n",
    "IIT for model distillation [ Wu\\*,Geiger\\*, Rozner, Kreiss, Lu, Icard, Goodman, and Potts (2021)](https://arxiv.org/abs/2112.02505)\n",
    "\n",
    "Interchange intervention training is a method for training a neural network to conform to the causal structure of a high-level algorithm. Conceptually, it is a direct extension of the causal abstraction analysis we just performed, except instead of **evaluating** whether the neural network and algorithm produce the same outputs under aligned interchange interventions, we are now **training** the neural network to produce the output of the algorithm under aligned interchange interventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 590. Training loss did not improve more than tol=1e-05. Final error is 0.001175935372884851."
     ]
    }
   ],
   "source": [
    "V1 = 0\n",
    "V2 = 1\n",
    "id_to_coords = {V1: alignment[\"V1\"], V2: alignment[\"V2\"]}\n",
    "\n",
    "X_base_train, X_source_train, y_base_train, y_IIT_train, interventions = get_IIT_equality_dataset(\"V1\", embedding_dim ,10000)\n",
    "\n",
    "model = TorchShallowNeuralClassifierIIT(hidden_dim=embedding_dim*4, hidden_activation=torch.nn.ReLU(), num_layers=3, id_to_coords=id_to_coords)\n",
    "_ = model.fit(X_base_train, X_source_train, y_base_train, y_IIT_train,interventions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      5000\n",
      "           1       0.65      0.65      0.65      5000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.65      0.65     10000\n",
      "weighted avg       0.65      0.65      0.65     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_base_test, X_source_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V1\", embedding_dim,10000)\n",
    "\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_source_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_base_test, base_preds))\n",
    "print(classification_report(y_IIT_test, IIT_preds))\n",
    "\n",
    "\n",
    "X_base_test, X_source_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V2\", embedding_dim,10000)\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_source_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_IIT_test, IIT_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we now have perfect IIT accuracy **V1** meaning that under this alignment the neural network computes whether the first pair of inputs are equal. However, we still have low IIT accuracy for **V2**, meaning that under this alignment the neural network doesn't compute whether the second pair of inputs are equal.\n",
    "\n",
    "This is expected, because we only trained the network to compute **V1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the network to compute both **V1** and **V2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 772. Training loss did not improve more than tol=1e-05. Final error is 0.3725438618566841."
     ]
    }
   ],
   "source": [
    "model = TorchShallowNeuralClassifierIIT(hidden_dim=embedding_dim*4, hidden_activation=torch.nn.ReLU(), num_layers=3, id_to_coords=id_to_coords)\n",
    "\n",
    "\n",
    "v1data = get_IIT_equality_dataset(\"V1\", embedding_dim ,10000)\n",
    "v2data = get_IIT_equality_dataset(\"V2\", embedding_dim ,10000)\n",
    "X_base_train = torch.cat([v1data[0],v2data[0]], dim=0)\n",
    "X_source_train = torch.cat([v1data[1],v2data[1]], dim=0)\n",
    "y_base_train = torch.cat([v1data[2],v2data[2]])\n",
    "y_IIT_train = torch.cat([v1data[3],v2data[3]])\n",
    "interventions = torch.cat([v1data[4],v2data[4]])\n",
    "\n",
    "_ = model.fit(X_base_train, X_source_train, y_base_train, y_IIT_train, interventions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5000\n",
      "           1       0.99      0.99      0.99      5000\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       1.00      1.00      1.00      5000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_base_test, X_source_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V1\", embedding_dim,10000)\n",
    "\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_source_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_base_test, base_preds))\n",
    "print(classification_report(y_IIT_test, IIT_preds))\n",
    "\n",
    "\n",
    "X_base_test, X_source_test, y_base_test, y_IIT_test, interventions = get_IIT_equality_dataset(\"V2\", embedding_dim,10000)\n",
    "IIT_preds, base_preds = model.model(model.prep_input(X_base_test, X_source_test, interventions))\n",
    "IIT_preds = np.array(IIT_preds.argmax(axis=1).cpu())\n",
    "base_preds = np.array(base_preds.argmax(axis=1).cpu())\n",
    "print(classification_report(y_IIT_test, IIT_preds))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "933b0a94e0d88ac80a17cb26ca3d8d36930c12815b02a2885c1925c2b1ae3c33"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
